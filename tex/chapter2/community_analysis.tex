%\chapter{Microbial Community Analysis: Metagenomics and Metatranscriptomics}
%\label{chapter:B}

\section{Abstract}

Methane is one of the most potent and common greenhouse gases.
In nature, specialized bacteria called methanotrophs are able to consume methane as their only carbon and energy source.
Deeper understanding of these microbes sheds light on a significant remediator of naturally produced greenhouse gases.
Lake Washington's sediment has served as a model ecosystem for methanotrophy studies for several decades.
Recent advances in high-throughput sequencing technology provided opportunities to observe the complex communities supported by methanotrophic methane oxidation in a more natural state than has been possible.
This study analyses serial propagations of Lake Washington sediment, from both a metagenomics and metatranscriptomics perspective.
Inference of which microbes dominate the samples, and what metabolic functions are active are discovered.
The importance of oxygen for community composition and function is highlighted.

\section{Introduction}
\subsection{Lake Washington Methane Cycling Studies}

The Lidstrom Lab has studied methanotrophic oxidation of methane in Lake Washington sediment for decades.
Methanotrophs are concentrated at the transition from aerobic to anaerobic soil.
This interface corresponds to both availability of methane, which rises from below, and oxygen from above \cite{lidstrom1984gradients, kuivilal1988, auman2000gradients}. %, which is required because methane is more reduced than biomass.
This microenvironment is rich in methanotrophs, methylothrophs, and other species.
When natural sediment samples are incubated in the lab with methane as the only food source, a high abundance of non-methanotrophs is often supported \cite{oshkin2015LW}.
Many of the abundant non-methanotrophs are methylotrophs, presumably consuming methanol, an intermediate of methane metabolism.
There are also many species which can only eat multi-carbon compounds, and therefore must be consuming excreted organic multi-carbon compounds, or cell biomass.
Trends in the types of communities that form in these sediment incubations have been observed  \cite{oshkin2015LW}.
Some species pairs appear to occur more than others.
Understanding the metabolic diversity of methanotrophs and methylotrophs in the sediment will advance understanding of why certain partnerships tend to occur, as well as understanding of a significant natural greenhouse gas mitigation system.

%Isolates first, but now new tools
% good resource: Methylotrophy in a Lake: from Metagenomics to Single-Organism Physiology https://www-ncbi-nlm-nih-gov.offcampus.lib.washington.edu/pmc/articles/PMC3147377/#B20
Early studies addressed these questions by sampling specific types of DNA from Lake Washington sediment (e.g. \cite{auman2002, costello2002, nercessian2005}), and studying isolates for which genome sequences were not available \cite{auman2000gradients, kalyuzhnaya2005Methylosarcina, kalyuzhnaya2006methylotenera}.
Later, significant laboratory efforts were used to isolate and sequence more species known to thrive in Lake Washington
    \cite{kalyuzhnaya2011isolates, beck2015isolates, mctaggart2015, kalyuzhnaya2015} to better understand these communities.
%These single species' metabolism can be further studied with transcriptomics and other tools (e.g. Chapter \ref{chapter:A}).
% (doesn't fit!) These strains can also be used as reference DNA for aligning shotgun sequencing reads.
%Furthermore, mixtures of small number of these pre-defined strains can be used to probe the potential of different partnerships and the underlying biology \cite{yu2016synthetic}.

% meta
Awareness that not all microbes can be isolated \cite{kaeberlein2002, stewart2012}, and that microbes probably behave differently when growing in communities due to influence of other microbes \cite{yu2016synthetic} motivates study of these microbes in their natural community compositions.
The omics studies used on single cultures (e.g. Chapter \ref{chapter:A}) can be applied to communities, though analysis becomes much more challenging.
When omics methods are applied to mixed populations of organisms, the prefix "meta" is applied, resulting in the terms such as  "metatranscriptomics".
Correspondingly the term "metagenomics" is used to describe sequencing the DNA of the community to allow inference of the abundant taxa and their genetic composition.
Having the paired metagenomic and transcriptomic data allows estimation of gene expression for those microbes, by mapping sequences to the reference DNA identified from the metagenomes.

Previous metagenomics and metatranscriptomics studies of Lake Washington sediment have highlighted dominance of the methanotrophic family Methylococcaceae \cite{beck2013LW, beck2014LW, oshkin2015LW, hernandez2015LW} (Figure \ref{fig:taxonomy}).
These methanotrophs provide substrates for non-methanotrophic methylotrophs to grow \cite{beck2013LW}.
The particular methanotroph species and methylotroph species that dominate the sample is known to be influenced by oxygen availability \cite{hernandez2015LW}.
In previous studies, it was noted that low \ce{O2} tensions select for \mbox{Methylotenera/Methylobacter} partnerships whereas high \ce{O2} tensions select for  \mbox{Methylophilus/Methylosarcina} partnerships \cite{hernandez2015LW}.
There is also a revolving cast of non-methylotrops including Burkholderiales and Bacteroidetes \cite{kalyuzhnaya2008Burkholderiales, beck2014LW}.
Better understanding of the metabolic roles that each of these species play, and why certain partnerships tend to form would provide insight into this greenhouse-gas mitigating microbial community.

\begin{figure}[H]
\centering
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170311_taxonomy_overview.pdf}
    \begin{singlespace}
    \caption[Taxonomy of microbes known to factor into methane oxidation in Lake Washington sediment]{
       Taxonomy of microbes that often appear in methane incubations of Lake Washington sediment.
       The family Methylococcaceae is methanotrophic.
       The family Methylococcaceae includes non-methanotrophic methylotrophs.
       Burkholderiales grow on multi-carbon compounds, but in addition, some are methylotrophs.}
    \label{fig:taxonomy}
    \end{singlespace}
\end{figure}

\subsubsection{Goals of this study}
This study aims to identify the major methanotrophic, methylotrophic, and other microbial species that together enable methane consumption in Lake Washington, and deduce each taxa's contribution to the community metabolism.
Identification of which methanotrophs dominate in natural communities provides insights into how good past isolate studies reflect the true drivers of methane oxidation.
Identification of which metabolic pathways are expressed by these methanotrophs and the accompanying non-methanotrophs informs the mechanism of methane oxidation in this natural system.
Understanding each microbes contribution to the community metabolism allows hypotheses about genetic factors in methanotroph/methylotroph partnerships.

%For example, this study also aims to address the relative importance of two functionally redundant methanol dehydrogenase enzymes: Xox-MDH and Mxa-MDH. (cite).
%TODO: write more about this if I get results in the area.
%TODO: Some methylotrophs only have Xox.  So they are using it, or absent.

% --- How this dataset is poised to address these questions:    Experimental design: (don't make it too methodsy!)
The experimental design chosen to answer these questions is show in in Figure \ref{fig:experimental_design}.

\begin{figure}[H]
\centering
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170311_experimental_design_meta4--2_colors.png}
    \begin{singlespace}
    \caption[Experimental design]{
       Sediment from Lake Washington, which had been thawed from -80$^o$C and cultured in 8 different bottles,
        half of which were treated with low oxygen, and half of which were at high oxygen (see methods).
	   Bottles were serially transferred for a total of 14 weeks.
	   The last four bottles in each series are at the opposite oxygen condition of the original experimental design
        (indicated by bottle label color switch).
	   Metagenomes and metatranscriptomes were obtained for weeks 4-14, resulting in 88 metagenomes and 88 metatranscriptomes.
	   }
    \label{fig:experimental_design}
    \end{singlespace}
\end{figure}

This relatively simple experimental design, including high degree of replication for studies of this type, was chosen to provide statistical power despite differences across replicates and measurement noise.
Variation across replicates can arise from stochasticity as communities rarefy, and are compounded by the noise-generating steps of nucleic acid extraction, ribosomal RNA removal (in the case of metatranscriptomics), library prep, and the sequencing process.
The most important environmental variable identified so in previous studies, the oxygen availability, was modulated while holding all other variables constant.
Availability of sequenced isolate strains from the very ecosystem enhance exploration of the dataset by providing some ground-truth biological facts.
Lake Washington isolates can also be integrated into positive controls for many of the computational methods.

% --- Data sets like this are rare and special.
Though sequencing has become routine in most biological domains, this dataset is exceptional for several reasons.
Having four replicates for each experimental condition is much greater than typical metagenomic studies.
Furthermore, most metagenomics/metatranscriptomics studies are single timepoint snapshots, rather than time-series.
Having 11 samples in each series leads to a total of 88 samples.
For each of the 88 samples, untargeted metagenomes and metatranscriptomes were gathered.
These pairs allow exploration of the community without the restriction of referencing cultured strains' genomes.
RNA was depleted, so the majority of our sequencing information is about expressed genes.
In all the dataset totals to 9TB.

% --- Insights into what's challenging
Despite the size and replication of this dataset, answering the questions outlined above proved challenging.
%There are many additional challenges in moving from pure-culture 'omics to meta-'omics, and these challenges were amplified by the large size of the data.
First, the study aims to answer who is there, without the luxury of using reference DNA to align sequencing data to.
Thus, the first task is to assemble reference DNA from the vast number of short sequences provided.
This DNA then becomes the basis for answering both "who is there", and the reference for "what are they doing".
Ideally, the assembly yields a small number of long sequences.
More often than not, however, under-sampling of DNA or lack of punctuation in well-sampled (highly abundant) strains leads to fragmented reference DNA.
This fractured reference DNA carries uncertainty and information loss through the rest of the analysis, so care must be taken to interpret all downstream results (discussed in Figure \ref{fig:pipe_leaks}).

% -- Tool selection & evaluation is challenging.
Furthermore, tool selection and evaluation is challenging.
As discussed in the introduction, metagenomics and metatranscriptomics of natural microbial communities is a rapidly developing field laiden with methodological challenges.
For each step of inference, there are numerous tools utilizing different approaches one must choose from.
Given that each tool has different efficacy for different data sets, several tools are usually tried for each step.
For each tool, there are numerous tuning knobs the author encourages exploring, leading to a combinatiorial explosion of potential outcomes for each inference step.
The nearly complete turnover of tools approximately every 5 years leads to very few benchmarking studies, and review papers that are out date within months of publication.
Benchmark studies comparing tools are rare and specific to a small number of data sets that may not behave like your own data set.
%Methods and metrics for tool evaluation are not standardized. repeated below

% --- Lack of standards in field
The field also lacks standards for assessing the efficacy of each inference step.
This is in part due to differences in goals across metagenomics/metatranscriptomics studies: some aim for high confidence inference about a specific sub-population such as a novel taxa, whereas others aim to describe the sample more broadly.
Many tools provide only limited insight into their efficacy on your particular dataset.
Care must be taken by the investigators to select the right tools, connect them properly, and evaluate results critically.
Often the trade-offs between tools are not evident until they are tested, and the data is explored with a critical eye.
Success in this field requires iteration as these insights are developed.

% --- So Big!
Furthermore, the size of this dataset is both luxurious and challenging.
Yes, the high degree of replication and number of samples per series is essential for identifying hypotheses in noisy data.
However, many computational tools are not designed to scale to input data of our size, and fail when used on larger datasets than they were developed for.
While some fail quickly and with informative messages, other simply fail by running indefinitely without the tool either completing its task or aborting.
For some goals, the data can be broken into subsets, processed separately, and re-joined upon completion.
However, not every tool can operate on segments of the data, and extra care is required when stitching together results such that the next tool downstream is blind to such manipulations.
Despite the challenges, this thesis provides a coarse description of which microbes are present, and what they contribute metabolically.
Steps to zoom in on particular microbes to tell more detailed stories about a subset of the population are outlined as future directions.


%==========================================================================================================================================
%==========================================================================================================================================
%==========================================================================================================================================
\section{Metagenomics and Metatranscriptomics}

\subsection{Introduction to Metagenomics and Metatranscriptomic Inference}
Metagenomics and metatranscriptomics are umbrella terms for any project that uses sequencing of mixed populations of organisms.
It implies untargeted sampling of the samples' entire DNA or RNA pool, rather than selecting for specific types of sequences.
This is in contrast to 16S surveys, which amplify DNA from a segment of the conserved bacterial 16S ribosome \cite{kunin2008}.
Such sequences are used as a molecular clocks for large timescales, and allow for inference of the bacterial taxa present in samples.
16S studies do not allow the possibility to determine what genes each organism has available.
Sometimes two organisms are nearly identical at the 16S level, but have substantial metabolic differences due to insertions, deletions, and transposons.  % todo (cite) (tried for 20 min).
The term "metagenomics" is typically reserved for the un-targeted sampling of the entire community DNA pool.
Metagenomics affords the possibility of identifying the genetic composition of individual microbes, albeit after much greater analysis efforts.
Prior studies of Lake Washington painted the coarse 16S-based perspective of who is present in Lake Washington's sediment \cite{beck2013LW, hernandez2015LW, oshkin2015LW}, and did preliminary untargeted metagenomics \cite{beck2013LW, oshkin2015LW}.
This work focuses solely on untargeted metagenomics, to address the more challenging questions of microbial genetic composition, and to provide a basis for expression analysis.

%---- Isolates vs de-novo reference-free assemblies.
Once shotgun metagenomic samples are in hand, there are many possible ways to infer which organisms are present and what they express.
One approach is to assess how the samples relate to isolate organisms, by mapping to the reads to the isolates' genomes.
High mapping rates to an isolate genome suggests the sample contained a large abundance of a similar organism.
If their genomes are similar, mapping of RNA can inform the expression patterns of that organism in the sample.
This can afford an excellent benchmark for analysis of metagenomes or transcriptomes, but only if the isolate genomes accurately represent the strains and diversity of strains in the community sample.
However, isolates may often poor proxies for natural microbes given that the vast majority of isolates are not currently culturable \cite{kaeberlein2002, stewart2012}.
Even if the isolates are perfect proxies for some organisms, the set may be missing whole categories of other organisms.
This project did a preliminary study using isolate genomes as a reference for mapping metatranscriptome reads, but discovered that a small fraction of the RNA mapped to the genes in the isolate genomes (Figure \ref{fig:isolate_RNAseq}).
The project quickly pivoted to reference-genome-free workflows, whereby the metagenomic reads were assembled into contigs that collectively represent the DNA present in the dominant and semi-abundant microbes.
These contigs can be annotated to identify genes, and organised into genome bins intended to represent single strains or groups of highly similar strains.

\begin{figure}[H]
\centering
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170312_metagenomics_metatranscriptomics_overview.pdf}
    \begin{singlespace}
    \caption[Overview of metagenomics/metatranscriptomics workflow]{
       Graphical introduction to basic vocabulary and inference steps of metagenomics and metatranscriptomics workflows.
	   Short colored lines = single reads, long colored lines = contigs,
	   gray arrows on colored lines = gene calls, wiggly lines above contigs depict coverage of alignment.}
    \label{fig:meta_workflow}
    \end{singlespace}
\end{figure}

The high-level representation of steps common to most shotgun metagenomics papers is shown in Figure \ref{fig:meta_workflow}.
The first step of reference-free metagenomics is assembly, wherein contigs are aligned and fragments are merged to infer the sequence from which the reads originated.
Binning aims to identify contigs that in aggregate represent single organisms, or groups of highly related organisms \cite{kunin2008}.
Genes can be called on the contigs, either before or after binning, to reveal the genetic potential of the parent organism.

The flow of information through metagenomics pipelines can be thought of as liquid flow through piping with leaks (Figure \ref{fig:pipe_leaks}).
In the process of aggregating information, each software step can lose information ("leak") along the way.
Flow (read accountability) can be measured at the input and exit of pipes (represented by flow gauges), allowing identification of how well output data reflects the original samples, and at which step(s) information was lost.

\begin{figure}[H]
\centering
    \includegraphics[width=0.8\textwidth]{./tex/chapter2/figures/170312_pipe_leaks.pdf}
    \begin{singlespace}
    \caption[Framework for assessing information loss in workflow steps]{
        Cartoon representing the ability to deduce information loss at different steps of the metagenome/metatranscriptome workflow.}
    \label{fig:pipe_leaks}
    \end{singlespace}
\end{figure}

%---- Pipe description
A simplified cartoon of the framework used to assess efficacy of each tool in the workflow is illustrated by Figure \ref{fig:pipe_leaks}.
For papers where the goal is to describe one or several novel organism(s) with high confidence, the loss of information (reads) along the way may not be a significant concern.
Often papers in this category do not clearly report an estimate of that organisms abundance in the natural community.
% Don't trash other papers \cite{evans2015} , or obscure absolute abundances by using relative abundances \cite{daly2016}.
Other papers try to describe a more holistic description of the community \cite{kantor2017} by describing the diversity of organisms found in bins from the sample.
In this case, it is crucial to quantify what fraction of the original sample is described by the output of your analysis.
These statistics are usually not stated clearly, allowing readers to over-estimate the importance of the described taxa in the real ecosystem.
% At this stage, or research is in this camp, and the result section will highlight how this frame of mind guided selection of tools.
The pipe analysis framework illustrates the approach of this paper: use multiple monitoring methods to determine which pipeline steps are associated with information loss.
These statistics are reported throughout to prevent misinterpretation of claims about the community compositions and expression patterns.
%This thesis aims to describe the community holistically, and thus strives to clearly report assembly, binning, and read mapping effacy so as to not overstate claims or exaggerate community simplicity.
% Many literature studies report small and incomplete descriptions about efficacy of their assembly and binning, which obfuscates leaks in the analysis pipeline and corresponds to over-simplified descriptions of the environment under study.  % Don't cite: hard to be ceratin I read carefully enough to call out papers by name.  It's also not nice!

%----- There is no road map!
Each arrow can be executed by several or sometimes dozens of competing software packages \cite{sangwan2016,thomas2012}.
Each tool can report basic statistics about efficacy based on inputs and outputs, but it it up to the researcher with larger-scope understanding of the project goals to write scripts to critically assess efficacy of the tools in aggregate.
Results from one software package can give you better insight about how to evaluate the other packages' results, so an iterative process with various somewhat-equivalent tools can maximize the accuracy of your results.

Another challenge of projects of this scope is the size of the data.
While more data is great for software tools trying to extract information from uncertain data, many tools are not designed to work on sequencing data as large as this one.
%Tools choke.  Just don't complete.
Sometimes the parameters can be altered, sometimes you can break up a dataset and feed it to a tool in pieces, but sometimes the size is a deal breaker.

It is the role of the computational biologist to learn enough about the competing tools to select a handful to try, develop metrics and priorities for the trade-offs of each tool, project complex data into summary graphs, and decide which tool is the best fit for the research goals.

\subsubsection{Assembly}
%---- Why assemble
Analysis of metagenomic and metatranscriptomic data usually beings with assembling metagenome reads into contigs (Fig \ref{fig:meta_workflow}), which are contiguous stretches of genomic sequence in which the order of bases is known to a high confidence level. %(JGI)
The metagenomes can be aligned to these contigs to infer the abundance of organisms.
The transcriptomes can be aligned to these same contigs to infer what genes are expressed.
In principle, metagenomes and metatranscriptomes can be aligned to isolate genomes rather than contigs, however, in practice meta-omics experiments are used precisely when the isolates available are known to be incomplete representatives of the microbial community under study.
Even if a similar organism has been isolated, the investigation may be probing the diversity of similar organisms, or the influence of less abundant microbes on the community's function.

%---- Not all assemblies are created equal
The challenge of assembly scales with the complexity of the microbial community.
High species diversity and strain-level heterogeneity add challenge to assembly \cite{kunin2008, thomas2012}.
Communities with a small number of well-delineated species tend to assemble better, yielding shorter numbers of long contigs.
In contrast, complex communities' high diversity can lead to assemblies with fewer long contigs and more short contigs \cite{kunin2008}.
These shorter contigs are more challenging to analyze and can lead to an incomplete portrait of a community.
Short contigs are more difficult to call genes on, and are also more difficult to bin because measures like GC and differential abundance are noisier for short contigs than long ones \cite{sangwan2016}.
The most common measures of assembly efficacy are characteristics of the contigs themselves.  How many are there?  What is the length of the contig that divides the length-sorted contigs into a pair of equal lengths (termed "N50")?
This thesis advocates for an additional measure not seen in other published work: the fraction of the original reads that map to the assembled contigs.   % todo: "seldom seen" instead of "not seen"?
% Dont' talk about restricting to contigs > 1.5kb.

\subsection{Elviz Assemblies}
%---- JGI assemblies
Many sequencing projects including this one are done by the Joint Genome Institute (JGI), which provides some bioinformatics processing in addition to providing un-processed reads.
The software they run assembles contigs for each sample individually, predicts genes, and calls taxonomy for contigs \cite{cantor2015}.
They also report the number of reads and average coverage for each contig.
These measures are a great starting point for answering "who's there" in terms of taxa abundance, but does neglect information about reads that did not assemble well and thus must be used with caution.

%---- Not assembled together
The contigs JGI provides are assembled for each sample, individually.
For this project, that means there are 88 separate assemblies.
Thus the contigs are not shared across samples, and comparison across samples is hindered.
For example, it is difficult to infer whether a particular gene is differentially expressed across two samples if the contigs used as reference DNA are not the same across samples.
More powerful analyses can be done when the DNA from all metagenomic samples are assembled at once.
This makes it possible to get a table of gene expression that is comparable across samples.
Such an assembly also leads to more powerful binning (discussed below) by providing extra features to cluster with: the differential abundances of each contig across the n samples \cite{albertsen2013}.
Since the number of reads originating from a particular organism should be proportional to its abundance, the DNA coverage for a set of contigs originating from an organism should be similar in a particular sample, and correlated across samples.
The per-sample nature of the JGI contigs restricted the types of analyses that data was used for, and motivated generation of co-assembled contigs to represent the entirety of the dataset as discussed below.

\subsubsection{Binning}
%---- Definition & Why
Desire for understanding at organism-level often leads investigators to approximate genomes as best they can from a set of metagenomic contigs.
The phrase "genome bin", often called simply "bin", is used to describe a collection of contigs used to approximate a single organism's genome.
"Bin" implies the collection is expected to be somewhat incomplete and potentially contaminated by DNA of other strains or species.
Bins allow inference of which metabolic pathways are available, and can be used as a reference to map RNA to for quantification of how these genes are expressed.
Higher confidence claims would be possible upon isolation of the organism represented by the genome bin, but laboratory isolates are often not obtainable either due to obligate partnerships with other organisms, or a variety of intolerances to laboratory conditions \cite{stewart2012}.
Binning can be done before or after annotating genes on the contigs, as very few methods use gene calls in the binning process.

%---- Overview of binning tools' strategies
The most common features used to bin contigs include contig GC content, tetranucleotide frequency, other oligonucleotide frequencies, and differential abundance across samples \cite{sangwan2016}.
Most aim to be effective without needing reference genomes to align to.
% can't find citation for using an isolate as a binning reference.  Only for assembly.  Drop??

%---- Rarefaction, species heterogeneity
The ability to get clean genome bins varies greatly from project to project.
As with assembly, more rarefied samples with low levels of strain heterogeneity are more amenable to binning \cite{kunin2008, thomas2012}, as the contigs are more likely to be long and few in number.
Longer contigs have reduced noise for measurements of GC ratio, tetranucleotide freq, and differential abundance \cite{sangwan2016}.
This in turn leads to less ambiguity when sorting contigs into respective bins.
Notably, most binning tools are demonstrated on simple communities such as the premature infant gut \cite{sharon2013}.
Thus, the assembly quality statistics noted in binning method papers is not likely to be reflected in analysis of these high-complexity samples.
% In fact, most binning methods were demonstrated using relatively simple communities (e.g., premature infant gut datasets of Sharon et al.

%---- Bin assessment
The quality of bins can be determined by combining metrics of completeness, contamination, and efficacy of representing the sample.
Completeness and contamination checks can be automated by use of CheckM \cite{parks2015}, which uses the presence of marker genes in each bin as the basis for its approximations.
The marker genes used by CheckM are different based on the approximate taxonomy CheckM approximates for the bins.
While this is certainly more effective than one set of genes used for all microbes, the reference sets available may not be good fits for the particular microbes under study.
Furthermore, the choice of reference gene set might be poor for messy bins that  contain contigs from wildly different taxa.
Some papers determine completeness and contamination by manual inspection using domain-specific marker gene sets (cite).
For papers published before CheckM, this was the best option, however CheckM does allow the possibility of adding custom marker gene sets to their analysis pipeline.

%---- Binning tools
The binning tools used herein combine sequence composition and coverage across multiple samples as inputs to machine learning algorithms to automatically cluster contigs into genomes.
Several were tried, given that differences in their algorithms and output characteristics are seldomly and vaguely reported \cite{sangwan2016}.
Metabat \cite{metabat2015} uses k-medoid clustering of a distance measure composed of tetranucleotide frequency and abundance.
% ** doesn't use marker genes **
MyCC \cite{mycc2016} uses affinity propagation to cluster contigs, and uses the presence of marker genes to correct clusters.
%"an automated binning tool that combines genomic signatures, marker genes and optional contig coverages within one or multiple samples"
%"FetchMG extracts 40 universal phylogenetic marker genes"
%"AP-generated clusters were finally corrected based on the sequences harboring marker genes"
CONCOCT \cite{concoct2014} uses a Gaussian mixture model fit with a variational Bayesian approximation, on features thinned out via principle components analysis (PCA).
% This says it uses marker genes, but the original paper doesn't mention it.
% Manual curation
Almost every high-quality bin published in high-profile papers has used tools such as these, but is subsequently refined by manual curation, with methods only vaguely described.

\subsubsection{Mapping RNA}
Metatranscriptomes can be mapped to contigs or bins.
A key variable to consider is what you want to happen with reads that map to multiple places.
If a read maps equally well to two different contigs in a bin, should it be randomly assigned to one locus, or thrown away?
If the study is aiming for differential expression type analysis, than the latter is better.
Discarding ambiguous reads is the default of most alignment and counting tools.
If the study aims instead to describe a holistic picture of expression in a sample, it may be worth guessing the source of the DNA, which will certainly be wrong some of the time.


%==========================================================================================================================================
%==========================================================================================================================================
%==========================================================================================================================================
\section{Methods}

\subsubsection{Experimental}  % Note that work was done previously, so I'm not implying I did it.
The culturing and sample preparation was done by Maria Hernandez, a visiting scholar.
Sediment stored in DMSO on previous sampling trip was thawed from -80$^o$C and distributed into 250 mL bottles containing 50mL of NMS medium \ref{fig:experimental_design}.
Samples started with XX amt of methane (XX mL), and either low oxygen (XX amt) or high oxygen (XX).
Bottles were serially transfered for 14 weeks.
The bottles were kept sealed (air-tight) between serial transfers; the gaseous compositions for the days between transfers were not measured.
Bottles were shakedn at XX RPM and held at XX$^o$C.
Metagenomes and metatranscriptomes were obtained for all samples corresponding to weeks 4-14.
Earlier weeks were omitted due to potential effects of residual DMSO, and interest in prioritizing sequencing of later, more-rarefied samples.
The oxygen conditions (low/high) were switched for the last 4 bottles in each series (see Figure \ref{fig:experimental_design}).

\subsubsection{Sequencing}
This large dataset was made possible by a Joint Genome Institute sequencing grant (cite the \#? XX).
JGI sequenced all samples on an Illumina platform to produce the 88 metagenomes and 88 metatranscriptomes.
Ribosomal RNA was removed before sequencing the metatranscriptomes.
%~ XX (?? Paired ended?) reads per sample, for both metagenomes and metatranscriptomes (??).

\subsubsection{Elviz Analysis}
Along with raw sequencing outputs (fastq.gz files) for each sample, Elviz data was provided \cite{cantor2015} by JGI.
These data included one assembly per metagenome, corresponding contig statistics, and transcriptome alignment statistics.
In addition, they provide taxonomy for each contig, to some degree of certainty: some contigs' taxonomy stops at family, while others are specified to the genus level.
The taxonomy, contig lengths, and number of reads mapped to each contig were used to infer the distribution of taxa in each sample.
The metric used was the fraction of reads assigned to contigs with the specified taxonomy (code at \url{https://github.com/JanetMatsen/elvizAnalysis/blob/master/abundance_utils.py}).
Length of contigs was not normalized out, or the abundance of short contigs would dominate the results.
The code checks that the taxas` abundances summed to 1 for each sample.

Tools were written to aggregate (a) based on taxonomy level, or (b) everything below a taxonomy level.
Contigs with taxonomy not desired to the specified level were grouped into "other".
This framework was also used to summarize abundances at mixed taxonomy level (e.g. phylum Bacteroidetes, order Burkholderiales, family Methylococcales, and family Methylophilales), and plotted (code: \url{https://github.com/JanetMatsen/elvizAnalysis/blob/master/abundance_plot_utils.py}).

Statistics for the 88 samples were merged with information about the oxygen, replicate, and week values corresponding to each sample using Python and Pandas.
Plotting was done with Matplotlib, Pandas, and Seaborn.

\subsubsection{Computational resources}
This computationally-intensive research was supported by research grant, which included \$27k and expert consulting on how to best utilize the vast services offered.
AWS allows per-hour rental of machines with different specifications, that the user can choose based on algorithm needs.
Furthermore, the ability to share machine images with other researchers greatly facilitates the potential reproducibility of research.
Upon project completion, an AMI encapsulating the entire data analysis pipeline will be provided so others can re-run our analyses.

The machine ("instance") type used in all methods to follow was an AWS c4.8xlarge instance, which has 36 cores and 60GB memory.
This was sufficient for all work, other than the memory-intensive assembly step, as noted below.
Instances could be turned on and off as needed, reducing compute costs.
This is in contrast to sharing a similar machine with the entire Beck Lab, which would have slowed down analysis and caused conflicts when certain computations used all of the compute resources, sometimes causing computer failure.

Each instance obtained data and wrote results to a shared file system.
The 9 TB of data, scripts, and results were stored using the AWS Elastic File System (EFS).
EFS is AWS's most versatile and highest performance (most expensive) file storage, which allows users to have multiple instances reading/writing to the same directory.
This shared nature of the files allows the user to spin up a second computer instance as needed, and read/write the exact same set of files.

%---- Computation parallelization
Parallelization of compute tasks was done by splitting jobs across a single large computer, or across separate EC2 instances.
When tasks were parallelized across one powerful computer was done with Gnu parallel or Python's \texttt{pool.map}.
When parallelizing across more, often weaker, computers, an AMI was made that mounts the EFS-stored data.
These instances were usually started by hand through the console, though proof of principle studies using the Amazon Command Line Interface (CLI),
    and an Autoscaling/SQS service pair were explored to set the foundation of future work (see repository XX) for the templates developed.

\subsubsection{Map to isolate genomes}
As a preliminary study, the metatranscriptomes were mapped to 55 genomes isolated from Lake Washington by the Lidstrom Lab.
The sequences were downloaded from NCBI, and concatenated together before mapping.
Mapping to the multi-fasta rather than the individual genomes prevents double-counting of reads that map well to multiple loci.
BWA-MEM \cite{li2009} with default settings was used to map each transcriptome to the multi-fasta, and htseq-count \cite{anders2014} was used to tabulate expression estimates.
Samtools \cite{li2009samtools} was used to evaluate mappings by BWA.
Note: the default of BWA is to flag reads that map equally well to two or more loci as having quality score 0; these reads are then not included in the tabulated results by gene-name.
This is the best-practice approach when doing differential abundance analysis, but does lead to under-estimation of gene expression levels and lower accountability of the original fastq reads. % TODO: cite

\subsubsection{Assembly} % (Dave)
Assembly to produce contigs was done on pooled quality-trimmed metagenome reads via Megahit \cite{li2015}.
This memory-intensive computation was done on an AWS instance with 1 TB of memory.
Assembly of multiple samples simultaneously provides a shared set of contigs to use when mapping DNA reads or RNA-seq reads from any of the 88 samples.
This in turn allows for comparison of gene expression across samples.
The fraction of reads represented by the assembly, in aggregate, were measured to verify assembly efficacy.
%Tune knobs until â€¦
%Followed protocol ...

\subsubsection{Gene calls}
Genes were called on contigs with length greater than or equal to 1.5kb using Prokka \cite{seemann2014}.
This was cutoff was selected because shorter contigs are not recommended for inclusion by most binning tools documentation.
Additionally, shorter contigs are less likely to have genes identified on them, as genes are more likely to be incomplete due to a higher density of contig edges.
Prokka did not tolerate an input size of the scale, so the input fasta was broken into 5 files of approximately equal size.
These were processed in parallel, using Python's \texttt{pool.map}.
A \href{https://github.com/BeckResearchLab/meta4/blob/master/m4b_binning/assembly/prokka/contigs/glue_together_gffs.py}{script} was written to merge the resulting annotated general feature format files (.gff files) into one representing all contigs $\geq$ 5kb.

\subsubsection{Checking contigs' ability to represent each metagenome}
The loss of information resulting from omitting short contigs was assessed by counting the number of reads that map to contigs $\geq$ 1.5kb, and comparing that to the total number in the raw metagenome fastq.gz files.
This represents an upper bound in information content for the assembly step.
Again, this used BWA-MEM \cite{li2009}, and a \href{https://github.com/BeckResearchLab/meta4/blob/master/m4b_binning/assembly/data/sample_info/count_reads_in_each_sample.sh}{script} written to count raw fastq reads.
Pandas (Python) was used to merge results together.

\subsection{RNA-seq: mapping to contigs $\geq$ 1.5 kb}
Like all other read mapping steps, transcriptomes were mapped with BWA-MEM (default settings), and per-gene results were summarized with htseq-count.
Contigs $\geq$ 1.5kb were used as reference DNA.
Metatranscriptomes were mapped to these contigs all at once, rather than to each bin individually in order to reduce over-counting.
This does result in reads mapping identically well to two places being thrown out, as mentioned earlier.
Results from each sample were merged using a 60GB RAM AWS instance, rather than SQL.
The fraction of transcriptome reads was compared to the total number in the input fastq files as a metric of information loss.

\subsubsection{Binning}

Binning of contigs into genome-like bins was explored using three different packages.
MetaBAT was used with default settings on contigs $\geq$ 1.5kb.
As promised by the documentation, it scaled well to large datasets and completed within about a day.

MyCC was used, but did not scale to data of our size well.
The large memory requirement of the underlying affinity propagation algorithm led to failures on this large dataset, when default settings were used.
At one time, it wrote so many small files that the machine crashed due to running out of inodes.
Iteration of settings suggested by the authors was required to get MyCC to complete on our big data.
Adjustment of the algorithm settings and the minimum contig length cutoff were iteratively tuned until results were obtained.
In the end, the largest data it could handle was using settings \texttt{56mer, lt 0.4, st 50}, on contigs $\geq 2.5$ kb.

Concoct was tried initially, but bins were never obtained.
This tool reports multiple potential clusters per conitg.
The solution for assigning contigs with conflicting information to bins was not developed in the time frame of this project.

\subsubsection{Average Nucleotide Identity}
Average nucleotide identity (ANI) was used to compare bins.
The underlying tool used was written by JGI. % TODO: cite.
Their tool calculates two-way global ANI measures, and reports the fraction of each genome that aligned.
The authors suggest removal of ribosomal RNA genes, which can have high ANI even for divergent organisms.
They do not, however, provide options or suggest a tool for this step.
Given that the ANI calculations intended only to give a rough idea of similarity between bins or bins and isolates, this step was not performed.
The tool was used to assessed ANI between all pairs of isolate genomes and MetaBAT bins.

\subsubsection{Additional bin characterization}

Completeness and contamination were checked with CheckM \cite{parks2015}.
CheckM uses marker genes from what it determines to be an evolutionarily similar microbe.
The tool was benchmarked on isolates, to ensure it performed well on the key methylotrophic taxa under study.
Custom marker genes specific to methylotrophs were not added, however, this is suggested as a possible future direction to assess bins.

Taxonomy was approximated using PhyloPhlan \cite{segata2013}, and by ANI similarity with isolate genomes.

\subsubsection{Code}
The code described was developed with Git version control, and the full history is available on GitHub:
\begin{itemize}
    \item \textbf{ElvizAnalysis}: \url{https://github.com/JanetMatsen/elvizAnalysis}
    \item \textbf{meta4} (assembly, binning, etc.): \url{https://github.com/BeckResearchLab/meta4}
\end{itemize}

%==========================================================================================================================================
%==========================================================================================================================================
%==========================================================================================================================================
\section{Results and Discussion}


%-------- Elviz Analysis
\subsection{Raw Reads}

The cumulative number of raw and un-filtered reads is shown below.
This collection of reads was used for all inferences described in this chapter.

\begin{table}[H]
\centering
\begin{tabular}{l | cc}
 %\toprule
        & mean \# reads per sample & total \# reads \\
\midrule
	metagenomes & \texttt{3.28e+07} $\pm$ \texttt{7.24e+06} & \texttt{2.89e+09} \\ % /work/jmatsen/170308_assess_Elviz_read_attraction_frac
	metatranscriptomes & XX & XX \\
%\bottomrule
\end{tabular}
\caption{Total number of un-filtered reads.}
\label{table:sample_read_sizes}
\end{table}



%-------- Elviz Analysis
\subsection{Elviz Analysis}

The best measure of which taxa dominate the samples comes from the Elviz \cite{cantor2015} data.
As described in the Methods section, the measure used sum of read counts across contigs with the taxonomy of interest.
Traditional metrics like RPKM \cite{mortazavi2008} and TPM \cite{wagner2012} are excellent for comparing coverage or expression across features or samples, but could not be used due to the need to sum values across contigs.
In particular, a contig with length 10kb should contribute nearly identically to a measure of abundance as an identically expressed second 10kb stretch of DNA that for technical reasons was assembled into two 5kb stretches rather than one 10kb one.
Any scheme that controlled for contig length or was weighted by each contig's statistic would skew the aggregated number down for metagenomic datasets such of this with many short, low-coverage contigs.
The fact that these assemblies are dominated by short contigs means that RPKM and TPM would bias the statistics toward the statistics of the shorter and less reliable contigs.
Similarly, median coverage was not used or the unreliable coverage numbers associated with short contigs would dominate the measure.

Figure \ref{fig:4dominant_groups} shows abundances of the four major taxonomic groups, Methylococcales, Methylophilales, Bacteroidetes, and Burkholderiales, according to the Elviz taxonomy calls for each contig.
(Recall introductory Figure \ref{fig:taxonomy} for a hierarchical visualization of these taxonomies.)
Their dominance is consistent with pervious studies \cite{beck2013LW, beck2014LW, oshkin2015LW, hernandez2015LW, kalyuzhnaya2008Burkholderiales}.
Figure \ref{fig:dominant_genera} show the breakdown of the methanotrophic and methylotrophic taxa in Figure \ref{fig:4dominant_groups}.
Notably, the path to rarefaction is not particularly consistent across samples.
Like previous studies, dominance the dominant methanotrophic Order/Genus was Methylococcales/\textit{Methylococcaceae} and the dominant non-methanotrophic methylotrophic Order/Genus was Methylophilales/\textit{Methylophilaceae}.
Low oxygen was associated with a higher abundance of methanotrophs, and lower proportion of methylotrophs than the high-oxygen samples.
\textit{Methylosarcina} is often found in high-oxygen samples, but rarely in low-oxygen samples.
Two high oxygen samples are dominated by \textit{Methylobacter}, but the others are not.
The last four samples in each series are more similar to the previous samples in the series than samples at the opposite oxygen tension.


\begin{figure}[H]
\centering
    % /Users/janet/elvizAnalysis/ipython_notebooks/plots/
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170413_4_main_groups.pdf}  % ElvizAnalysis
    \begin{singlespace}
    \caption[Four major taxonomic groups in Lake Washington sediment incubations]{
        Fractional abundances of DNA from the four major taxonomic groups in Lake Washington sediment incubations:
	    Phylum Bacteroidetes, Orders Methylococcales (methylotrophs), Methylophilales (non-methanotrophic methylotrophs), Burkholderiales.
        Vertical gray line indicates the week the oxygen conditions were reversed.
        }
    \label{fig:4dominant_groups}
    \end{singlespace}
\end{figure}

\begin{figure}[H]
\centering
    % /Users/janet/elvizAnalysis/ipython_notebooks/plots/170313_methanotroph_methylotroph_taxa--portrait.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170313_methanotroph_methylotroph_taxa--portrait.pdf}  % ElvizAnalysis
    \begin{singlespace}
    \caption[Dominant methanotrophic and methylotrophic Genera]{
        Fractional abundance of DNA from dominant methylotrophic Genera.
        Purple bars are methanotrophs of Order Methylococcales, Family \textit{Methylococcaceae}
            (represents major taxa in blue bars of Figure \ref{fig:4dominant_groups}).
        Green bars are non-methanotrophic methylotrophs of Order Methylophilales, Family \textit{Methylophilaceae}
            (represents major taxa in yellow bars of Figure \ref{fig:4dominant_groups}).
        See Figure \ref{fig:taxonomy} for taxonomy reference.
        Vertical gray line indicates the week the oxygen conditions were reversed.
        }  % Italics are used for bacterial and viral taxa at the level of family and below.  https://wwwnc.cdc.gov/eid/page/scientific-nomenclature
    \label{fig:dominant_genera}
    \end{singlespace}
\end{figure}

\subsubsection{Binning Potential: Elviz Contigs}

%Genomic-scale resolution drove investigation of the potential for sorting these contigs into genome bins.
The goal of this study is a comprehensive description of the samples, ideally in terms of genome bins.
The potential for these Elviz contigs to paint a comprehensive picture of the microbial community was measured by summing all reads assigned to contigs long enough to bin, namely contigs $\geq$ 1.5kb.
Figure \ref{fig:isolate_RNAseq} shows that while the entire set of contigs represents the samples well, the subset of contigs that are candidates for binning explain less than 20\% of the reads obtained for many low oxygen samples.
Another complication of binning these contigs, is that binning the contigs for each sample individually would lead to many redundant bins that need to be thinned.
This process is prone to human bias, and can lead researchers to over-fit their bins to their quality measures and thus over-state the quality of their bins.
Nonetheless, if a particular sample is enriched in an organism of interest, use of the contigs from that sample should be conisdered for future binning efforts.


\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/meta4_bins_data_and_files/1703014_is_Elviz-_junk_revised/results
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170314_Elviz_is_not_for_binning--landscape.pdf}  % ElvizAnalysis
    \begin{singlespace}
    \caption[Upper-bound limit on success of binning Elviz contigs]{
        The upper-bound limit on success in binning Elviz contigs, as measured by the fraction of metagenome reads mapped to contigs.
        Lines are colored by replicate.
        Solid lines represent the fraction of reads in the raw .fastq file that map to contigs on any length.
        Dashed lines represent the fraction of reads in the raw .fastq file that map to contigs $\geq$ 1.5kb in length.
        Less than 20\% of the fastq would be explained by aggressive binning of most low oxygen samples.}
    \label{fig:dont_bin_Elviz}
    \end{singlespace}
\end{figure}

% ----- Map to Isolate Genomes ------
\subsection{Map to Isolate Genomes}

The next simplest approach of identifying which microbes are active in the samples, and what they express is to map the reads to the 55+ isolate genomes at hand (cite XX).
The potential efficacy of these results can be measured by quantifying the fraction of metagenomic and metatranscriptomic reads that align to these genomes (recall the pipe diagram, Figure \ref{fig:pipe_leaks}).
Figure \ref{fig:isolate_RNAseq} shows the fraction of the metatranscriptomes that can be explained using these reference genomes.
The low accountability (mostly $<$15\%) guarantees an incomplete portrait of the activity in these samples, so the data was not pursued further.
Despite heroic Lidstrom Lab efforts to isolate strains, the set obtained thus far do not cover the complexity seen in real samples.
This indicates missing taxa and/or dissimilarity between the isolated strains and the ones that dominate in nature.
While this method of describing gene expression was not pursued father, it provides a baseline fraction of RNA mapped for any subsequent metagenomic methods to beat.


\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/thesis/tex/chapter2/figures/170208_fraction_of_transcriptome_reads_mapped_to_isolates.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170208_fraction_of_transcriptome_reads_mapped_to_isolates.pdf}
    \begin{singlespace}
    \caption[Measure of isolate genomes' ability to account for RNA-seq reads]{
        Measure of isolate genomes' ability to account for RNA-seq reads.
        Each dot represents the total fraction of raw reads assigned to genes when mapped to a concatenation of 55 isolate genomes.
        }
    \label{fig:isolate_RNAseq}
    \end{singlespace}
\end{figure}

% ----- ASSEMBLY ------
\subsection{Assembly}

Given that the Elviz contigs and isolate genomes were not effective reference DNA for answering the questions of this study, a better set of contigs was sought out.
One approach for explaining a set of metagenomic samples is co-assembly of metagenome reads, calling genes on the resulting contigs, mapping the transcriptomes to these contigs, and tabulating the expression levels.
Accordingly, the metagenomes from almost every sample were pooled and assembled into one set of contigs shared by all samples.

Assemblies which produce long contigs are desired, as longer contigs are easier to call genes on and cluster by similarity during binning.
Communities with extremely low complexity (just a few microbes co-existing) can yield long contigs that can be sorted into high-confidence genome bins that are often described by authors as genomes, rather than bins.
As complexity increases, lessened sequencing depth and homologous regions between organisms inhibit the ability to get long contigs.
The distribution of contigs obtained (Figure \ref{fig:contig_lengths}) do not indicate a simple community.


\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/meta4_bins_data_and_files/170124_current_metabat_analysis_figures/170123_frac_reads_binned_at_different_contig_lengths_and_total.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170123_frac_reads_binned_at_different_contig_lengths_and_total--INKSCAPED.pdf}
    \begin{singlespace}
    \caption[Distribution of contig sizes]{
        Distribution of sizes for contigs assembled by MEGAHIT (2,617,225 contigs in total).}
    \label{fig:contig_lengths}
    \end{singlespace}
\end{figure}



% ----- ANNOTATION ------
\subsection{Annotation}

Genes were called on contigs with length $\geq$ 1.5kb, in preparation for metatranscriptome studies.
Prokka identified XXX distinct genes, encoding XXX differently named proteins (Table XX).

\begin{table}[H]
\centering
\begin{tabular}{l | c}
 %\toprule
        & statistic  \\
\midrule
	total \# of genes & \texttt{XXXX} \\ % /work/jmatsen/170308_assess_Elviz_read_attraction_frac
	number of distinctly name genes & XX \\
%\bottomrule
\end{tabular}
\caption[]{}
\label{table:annotation}
\end{table}


% ?? Xox?
Prokka was able to identify the key methanotrophy/methylotrophy genes such as XXX.
Some proteins were mis-annotated, as is typically observed when using automated annotation tools on methylotrophs.
For example, many of the glucose dehydrogenases identified are in fact methane monooxygenases, and Xox-MDHs are listed as XXX.

% ?? TODO: make a plot that shows the gene density is lower on short contigs?


% ----- TRANSCRIPTOME ANALYSIS ------
\subsection{Transcriptome Analysis}

% Intro
Mappings of the 88 transcriptomes to the annotated contigs revealed which of the 0.7XX million genes were strongly expressed.
Table XX shows the gene names associated with the highest total of reads mapped, and how many copies of these genes contribute to that sum.
See supplemental file XX for the full set.
The presence of key methanotrophy and methylotrophy genes agrees with the Elviz portrait of methanotroph/methylotroph dominance in every sample.
Other highly expressed genes allow speculation for metabolic roles of other microbes.
%Phage.

%?? Get isolate stats?? We hoped to beat the benchmark of mapping to the isolates:  median XX %.

Figure \ref{fig:rna_mapping_bars} shows how well the called genes account for the transcripts seen in the raw sequence data.
The green bars represent a high degree of certainty.
Gray bars correspond to "no feature", which is likely correlated to short contigs for which gene calls are less likely.
Pink bars are labeled as having low alignment quality, but recall that BWA-MEM sets the quality score to zero when a read maps equally well to two different spots.
It may be possible to improve (shrink) the gray bars via re-assembly.
Similarly, recovery of reads that map equally well to different places can be brought out of the pink bars if htseq-count's parameters are altered to allow low quality reads to be counted.
While this alteration would help with describing holistically which genes are expressed, it reduces certainty of read mappings and is not desired for Chapter \ref{chapter:C}.


\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/meta4_bins_data_and_files/1703016_frac_RNA-seq_mapped/figures/170316_fracs_mapped_unmapped_etc.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170316_fracs_mapped_unmapped_etc.pdf}
    \begin{singlespace}
    \caption[Efficacy of mapping RNA-seq to MEGAHIT contigs]{
        Efficacy of mapping RNA-seq to MEGAHIT contigs.}
    \label{fig:rna_mapping_bars}
    \end{singlespace}
\end{figure}

\subsubsection{Highest Expressed Proteins}
% TODO: add table of highest expressed proteins, and describe.

\subsubsection{Expression of Genes by Locus}

Which copes are expressed, and under which conditions?
Breaking down the expression of these genes by locus and sample reveals which copies dominate.
Many of the patterns appear to be oxygen-dependent.
% TODO: figure of expression.  Include more in appendix.
% FIGURE: pmo subunit A.

For example, the top \textit{pmoC} copies are strongly correlated to the oxygen tension in each sample.
Identifying which taxa are associated with these oxygen-dependent patterns in gene expression can shed light onto how oxygen influences community composition.
For example, this \textit{pmoC} trend was XXXX. %TODO


% ----- BINNING ------
\subsection{Binning of Co-assembled Contigs}

Contigs of length $\geq$ 1.5kb were binned by MetaBAT and MyCC, two leading binning tools.
As mentioned, MyCC does not scale well to large data, so the full dataset including contigs as short as 1.5kb did not complete, even with a high performance AWS instance.

\begin{table}[H]
\centering
\begin{tabular}{l | cc}
 %\toprule
            & \# bins & \% min contig size \\  % consider fraction of contigs binned?
\midrule
	MetaBAT & XX   & XX \\
	MyCC    & XX   & XX \\
%\bottomrule
\end{tabular}
\caption[Binning results: MetaBAT \& MyCC]
	{Binning results: MetaBAT \& MyCC.}
\label{table:sample_read_sizes}
\end{table}

%MetaBAT suffers from low binning rates, MyCC suffers from too aggressive of binning.
Figure \ref{fig:binning_frac_reads_mapped} shows this the fraction of the metagenomes that are accounted for by the bins, as a measure of how effectively the bins describe the composition of organisms.
The two sets of lines for the MetaBAT plots measure how well the bins did in total (dashed lines), and how well they did on contigs longer than 2.5kb (to better compare with the MyCC results).


\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/meta4_bins_data_and_files/170201_MyCC_read_accountability_figures/170201_comparable_read_coverage_for_metabat_and_mycc_3kb.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170201_comparable_read_coverage_for_metabat_and_mycc_3kb--INKSCAPED.pdf}
    \begin{singlespace}
    \caption[Fraction of reads accounted for by MetaBAT and MyCC bins]{
        Fraction of reads accounted for by bins generated via MetaBAT (min contig size = 1.5kb) and MyCC (min contig size = 2.5kb).
        Points represent the fraction of reads binned for each sample.
        The solid MetaBAT lines represent the fraction of reads associated with contigs of length $\geq$ 2.5kb, as an appropriate comparison to the MyCC run.
        The dashed MetaBAT lines represent the full fraction of reads accounted for by the MetaBAT results including contigs as short as 1.5kb.
        The arrow after week 10 indicates that all subsequent samples were treated with the opposite oxygen tension as the label indicates.
    }
    \label{fig:binning_frac_reads_mapped}
    \end{singlespace}
\end{figure}

MetaBAT with default settings produced bins with low sample accountability, whereas the MyCC bins represented a high fraction of the raw sample reads.
Figure \ref{fig:mycc_binned_more_contigs} shows this the fraction of the metagenomes that are accounted for by the bins, as a measure of how effectively the bins describe the composition of organisms.
The two sets of lines for the MetaBAT plots measure how well the bins did in total (dashed lines), and how well they did on contigs longer than 2.5kb (to better compare with the MyCC results).


\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/meta4_bins_data_and_files/170202_comparing_MyCC_to_metabat/170206_improved_fracs_of_contigs_binned_by_MyCC.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170206_improved_fracs_of_contigs_binned_by_MyCC.pdf}
    \begin{singlespace}
    \caption[MyCC binned contigs more aggressively than MetaBAT]{
        MyCC binned contigs more aggressively than MetaBAT.}
    \label{fig:mycc_binned_more_contigs}
    \end{singlespace}
\end{figure}

% MetaBAT comments
One striking trend in the MetaBAT results is the difference in the fraction of reads associated with binned contigs between low oxygen replicates 1/2 and 3/4.
This is explained by differences in the proportion of high-abundance contigs across replicates (Supplemental Figure \ref{fig:contig_dist}).
The poorly represented samples are biased more toward short contigs.
While noting that the last 4 data points in each series have the opposite oxygen condition as the series label, see that the high oxygen samples are better reflected by MetaBAT bins.
This source of this conundrum has not yet been resolved, but could be due to a smear of organisms for which assembly performed poorly.
BLAST could be used to identify the taxa for the contigs which are binning well, though high-throughput techniques would be prudent given the number of contigs.

Figure \ref{fig:mycc_binned_more_contigs} also shows MyCC's increased efficacy at representing the raw sequencing reads.
Upon further investigation, it was revealed that MyCC binned $>$99\% of all contigs supplied, including the shorter ($\approx$ 2.5kb) contigs which carry greater uncertainty. %(Figure \ref{fig:mycc_binned_more_contigs}).
Aggressive binning is associated with low specificity, binning of contigs that do not belong with the others in the bin.
Figure \ref{fig:mycc_contamination} reveals the consequence of this: high contamination scores according to CheckM.
CheckM's efficacy to analyze methylotrophs was confirmed by applying it to the 55 genomes used in the isolate studies.
The statistics it returned for these positive controls were nearly perfect, indicating that good bins for these samples should have nearly 100\% completeness and less than a few percent contamination (Appendix XXX).
% high sensitivity, low specificity.

\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/meta4_bins_data_and_files/170202_comparing_MyCC_to_metabat/170202_MyCC_has_higher_contamination.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170202_MyCC_has_higher_contamination.pdf}
    \begin{singlespace}
    \caption[MyCC has higher contamination than MetaBAT]{
        MyCC has higher contamination than MetaBAT.}
    \label{fig:mycc_contamination}
    \end{singlespace}
\end{figure}

Given the small fraction of the metagenomes explained by MetaBAT (Figure \ref{fig:mycc_contamination}), and high contamination scores of the MyCC bins (Figure \ref{fig:mycc_contamination}), binning has been placed on hold.
See Section \ref{chA_future_steps} below for suggested next steps in the binning workflow.

As a measure of the best-case scenario for binning given the assembly, the fraction of reads attracted to contigs shorter than 1.5kb were quantified (Figure XX).
If future work with these data aim to explore more than $\approx$ XXX\% of the data, other assembly strategies may be considered.
One possibility is to explore more parameters using the same MEGAHIT algorithm.
If the fraction of reads associated with short contigs does not improve, more laborious strategies can be considered.
For example, it is possible to take reads associated with long contigs out of the data, and re-assemble the leftovers.
A similar binning approach could be useful: removal of contigs that are in high-confidence bins, and assembling the leftovers.

% TODO: insert figure of upper-bound for binning potential of these metagenomes.


% ----- BIN TAXONOMY ------
\subsection{Bin Taxonomy}

Once final bins are in hand, taxonomic labels need to be assigned.
This can be done by aggregating information from several sources: the CheckM marker gene set (coarse label), PhyloPhlAn results (maximally specific), and average nucleotide identity (ANI, below).
PhyloPhlAn produced taxonomic labels for the MetaBAT bins.
These did not agree particularly well with the CheckM labels, increasing evidence that the current bins are not sufficient for holistic community descriptions.
% TODO: show data on this?  Put in Appendix?

% ----- ANI ------
\subsection{ANI}

ANI can also support taxonomic labels, especially in cases such as this project when there are many environmental isolates from the exact ecosystem to use as references.
The JGI ANI tool was used on all pairs of MetaBAT bins and isolate genomes, producing a large matrix of ANI values, a subset of which is shown in Figure \ref{fig:ANIs}.

\begin{figure}[H]
\centering
    % /Users/janet/Dropbox/thesis/tex/chapter2/figures/170123_frac_reads_binned_at_different_contig_lengths_and_total--INKSCAPED.pdf
    \includegraphics[width=1.0\textwidth]{./tex/chapter2/figures/170203_demo_of_ANI_heatmap.pdf}
    \begin{singlespace}
    \caption[Demo use of ANI to infer taxonomy of genome bins]{
        Demo use of ANI to infer taxonomy of genome bins.
        ANIs between all pairs of bins, and all isolate/bin pairs was computed, tabulated, and plotted to identify taxonomy of genome bins.
        This strategy, in conjunction with taxonomy calls by PhyloPhlAn \cite{segata2013} are recommended for taxonomic assignments when the final bins are identified.
        Plot produced by Seaborn clustermap.}
    \label{fig:ANIs}
    \end{singlespace}
\end{figure}

% ------ FUTURE STEPS
\section{Future Steps}
\label{chA_future_steps}


%Big picture
The goal of this analysis was to describe a wholistic picture of the microbes in the mixtures, and assess how gene expression supports methane oxidation.
This thesis identified the key trends, but more certain understanding can be gained by diving deeper into many topics described.
Insights gained by iterating through this pipeline have revealed possibilities to improving the analysis by modifying each step, as described in the following sections.

% ----- ASSEMBLY NEXT STEPS ------
\subsection{Assembly: Next Steps}

Like all steps of metagenomics, assembly in itself is an art.
Given a single data set, different assemblies could be better depending on the exact question to be asked.
For this thesis, the goal was a holistic portrait of which organisms are present in natural communities.
While the assembly used throughout this chapter was appropriate for that question, future explorations of the findings based on these contigs may reveal interesting organisms for which different binning strategies may identify better.

%Re-assemble to find rare ones
New assemblies could be done with the aim of making contigs that bin a particular organism well.
The enumerations of the taxa present in each sample, and the gene expression profiles and trends will be explored to identify uncultivated taxa to target.
For example, it is hypothesized that there is a "smear" of similar \textit{Methylobacters} for which we don't have isolates.
If genes thought to be associated with different \textit{Methylobacters} are found in particular samples, those could be re-assembled separately to get longer \textit{Methylobacter} contigs and thus better bins.
Perhaps there are some rare heterotrophs of interest; these too could be identified by gene expression patterns and assemblies could be done with the hope of contigs more amenable to binning those species.
Sequential binning and read removal.
Another possibility is to iteratively bin, remove reads that map to those bins, and re-assemble the leftovers.
This is a computationally expensive and likely laborious path to holistic community descriptions, but is possible.

% ----- BINNING NEXT STEPS ------
\subsection{Binning: Next Steps}

The analysis shown in this chapter highlights great opportunity to improve the bins and potentially allow for holistic descriptions of the communities.
The easiest step is to iteratively test MetaBAT's performance with different binning parameters as the authors suggest.
The resulting bins can be assessed, again by (a) CheckM completeness and contamination scores, (b) fraction of metagenomes that are attracted to bins, and (c) the fraction of transcriptomes that are attracted to them.
Special care can be taken to isolate different methylobacters.

In addition, there are many tools which have not yet been tried.
One promising tool from the Banfield Lab \cite{sieber2017} just appeared on the Biology preprint server, bioRxiv.
This tool is an ensemble tool that combines multiple binning algorithms (MetaBAT\cite{metabat2015}, MaxBin \cite{wu2015}, CONCOCT \cite{concoct2014} and tetraESOMs \cite{dick2009}), a generally advantageous strategy for machine learning.
It counts the number of single-copy marker genes in candidate bins, removes good looking bins, and re-bins the remaining contigs.


% ----- BIOLOGY NEXT STEPS ------
\subsection{Biology: Next Steps}

The dataset prepared in this analysis allows investigation of many biological questions.
Many of these questions are best answered with genome bins.
For example, one topic of excitement is understanding of two alternative methanol dehydrogenase systems.
Recently it has been discovered that some organisms prefer to use Lanthanum-dependent \textit{xox} methanol dehydrogenases, rather than the classically studied \textit{mdh} methanol dehydrogenases. %TODO: cite
Though Lanthanum was not intentionally supplied to these organisms, its possible that it was present in trace amounts.
Identification of expression levels of these two methanol dehydrogenase alternatives in these samples will be done soon.

Not all questions, however, require genome bins.
Building taxonomic trees of the various methane monooxygenase genes, and weighting them by observed abundance can give higher resolution insight into community composition than Figures \ref{fig:4dominant_groups}, \ref{fig:dominant_genera} shows.
There is also potential to explore signatures of phage in the existing contigs.


% ------ CONCLUSIONS
\section{Conclusions}

In conclusion, this 88-metagenome, 88-metatranscriptome data set was designed to allow discovery of dominant taxa in a rich microbial community.
The Elviz data was aggregated on taxonomic label to illustrate the fractions of the metagenomes attributed to different taxa.
These data were not appropriate for comparison across samples, or assembling into contigs, so an assembly was done with nearly all of the metagenomes.
These contigs were binned into a draft set of bins, which highlighted the challenge of getting enough good bins to illustrate an entire population's dynamics.
% TODO: suggest quality checks so we know how good the set is.

The contigs were annotated and the genetic content was explored.
In total, XXX genes were identified, encoding XXX different proteins.
Oxygen-dependent trends in locus expression were identified, supporting evidence that oxygen is an important and only somewhat understood factor in community composition and function.

The biology inferred in this preliminary round of studies drove new ideas for iterating through the pipeline again, with new goals and refinement strategies in mind.
While the samples may have too complex of a community structure for current binning tools to explain, targeting particular taxa for binning will allow observation of community dynamics for the major players.
In addition, the ability to extract more information about community structure and dynamics is explored in Chapter \ref{chapter:B}.


